{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMdc76bEjxUFIX1P3hucCjI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JayaManasa/speech-to-text-transcriber/blob/main/whisper_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3VpmSIzH5Q-",
        "outputId": "23a5f39d-1801-432d-d070-57c62297db52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcription:  ہاپی بات دیا سائل جا\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
        "import librosa\n",
        "\n",
        "# Load audio file\n",
        "audio_path = \"/content/sample_data/WhatsApp Ptt 2024-10-29 at 3.59.39 PM.ogg\"\n",
        "audio, sr = librosa.load(audio_path, sr=16000)\n",
        "\n",
        "# Initialize Whisper model and processor\n",
        "processor = WhisperProcessor.from_pretrained(\"openai/whisper-base\")\n",
        "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-base\")\n",
        "\n",
        "# Process audio\n",
        "input_features = processor(audio, sampling_rate=sr, return_tensors=\"pt\").input_features\n",
        "\n",
        "# Generate transcription\n",
        "predicted_ids = model.generate(input_features)\n",
        "transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)\n",
        "\n",
        "print(\"Transcription:\", transcription[0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "import torch\n",
        "\n",
        "# Initialize pipeline\n",
        "transcriber = pipeline(\n",
        "    \"automatic-speech-recognition\",\n",
        "    model=\"openai/whisper-base\",\n",
        "    torch_dtype=torch.float16,\n",
        "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        ")\n",
        "\n",
        "# Transcribe audio\n",
        "result = transcriber(\"/content/sample_data/WhatsApp Ptt 2024-10-29 at 3.59.39 PM.ogg\")\n",
        "print(\"Transcription:\", result[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFDTzFtQJTvg",
        "outputId": "550ad123-b55c-4715-cd5b-df4bde123c7c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcription:  ہاپی بات دیا سائل جا\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/whisper/generation_whisper.py:496: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
        "import librosa\n",
        "import torch\n",
        "\n",
        "def batch_transcribe_indian_english():\n",
        "    # Initialize model and processor once\n",
        "    processor = WhisperProcessor.from_pretrained(\"openai/whisper-base\")\n",
        "    model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-base\")\n",
        "    model.config.forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"en\", task=\"transcribe\")\n",
        "\n",
        "    # Directory containing audio files\n",
        "    directory = \"/content/sample_data/whatsapp\"\n",
        "\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith(\".ogg\"):\n",
        "            file_path = os.path.join(directory, filename)\n",
        "            try:\n",
        "                # Load and process audio\n",
        "                audio, sampling_rate = librosa.load(file_path, sr=16000)\n",
        "                input_features = processor(\n",
        "                    audio,\n",
        "                    sampling_rate=sampling_rate,\n",
        "                    return_tensors=\"pt\"\n",
        "                ).input_features\n",
        "\n",
        "                # Generate transcription\n",
        "                predicted_ids = model.generate(\n",
        "                    input_features,\n",
        "                    language=\"en\",\n",
        "                    task=\"transcribe\",\n",
        "                    temperature=0.2,\n",
        "                    no_repeat_ngram_size=3,\n",
        "                    num_beams=5\n",
        "                )\n",
        "\n",
        "                # Decode and save\n",
        "                transcription = processor.batch_decode(\n",
        "                    predicted_ids,\n",
        "                    skip_special_tokens=True,\n",
        "                    normalize=True\n",
        "                )[0]\n",
        "\n",
        "                # Save to file\n",
        "                output_filename = os.path.splitext(filename)[0] + \".txt\"\n",
        "                output_path = os.path.join(directory, output_filename)\n",
        "                with open(output_path, 'w', encoding='utf-8') as f:\n",
        "                    f.write(transcription)\n",
        "\n",
        "                print(f\"Transcribed {filename}: {transcription}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {filename}: {str(e)}\")\n",
        "\n",
        "# Run batch transcription\n",
        "batch_transcribe_indian_english()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hElF-mLdW7Sy",
        "outputId": "49279942-c027-4458-c12f-ccb529435e77"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed WhatsApp Ptt 2024-11-07 at 9.41.07 PM.ogg: all the pictures of the bride\n",
            "Transcribed WhatsApp Ptt 2024-10-30 at 8.06.52 AM.ogg: thank you for the new album happy geri geri san toshom\n",
            "Transcribed WhatsApp Ptt 2024-11-07 at 9.41.29 PM.ogg: you may pictures of dancing photos\n",
            "Transcribed WhatsApp Ptt 2024-11-07 at 9.41.03 PM.ogg: one pictures from red tarbun\n",
            "Transcribed WhatsApp Ptt 2024-10-29 at 3.59.39 PM.ogg: happy birthday saeeda\n",
            "Transcribed WhatsApp Ptt 2024-10-29 at 6.34.26 PM.ogg: i am jan madinath subhaka angelo chappinapadad nagaru lata viji kiran vanajak neelima narendar nayana andarki dhanyavadalu\n",
            "Transcribed WhatsApp Ptt 2024-11-07 at 9.40.54 PM.ogg: me photos of red dress\n"
          ]
        }
      ]
    }
  ]
}